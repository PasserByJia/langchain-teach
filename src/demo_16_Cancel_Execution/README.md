# 演示 16: 取消执行

在构建长时间运行的链或 LangGraph 代理时，我们可能希望在某些情况下（例如用户离开应用或提交新查询时）中断执行。本演示展示了如何使用 LangChain 表达式语言 (LCEL) 的运行时 `signal` 选项来中止正在进行的 `runnables`。

## 功能演示

`index.ts` 文件中的代码构建了一个检索增强生成 (RAG) 链，该链首先使用 Tavily 搜索网络，然后将结果传递给聊天模型以生成最终答案。演示包含以下四个示例：

1.  **正常调用**: 正常执行 RAG 链，获取关于旧金山天气的最新信息。

2.  **取消 `invoke` 调用**: 使用 `AbortController` 在 10 毫秒后取消 `chain.invoke()` 的调用。这展示了如何通过 `signal` 选项立即中止一个长时间运行的任务。从输出可以看到，执行在约 10 毫秒后就终止了，并且聊天模型从未被调用。

3.  **在流式传输中使用 `break` (对比)**: 这是一个对比示例，展示了在 `for await...of` 循环中使用 `break` 来停止接收流式数据块。需要注意的是，这种方式只有在第一个数据块开始返回后才能中断循环，因此耗时相对较长。

4.  **取消流式传输**: 与示例2类似，使用 `AbortController` 在 10 毫秒后取消 `chain.stream()` 调用。这展示了如何精确控制并提前中止流式传输，避免不必要的计算和等待。执行同样在约 10 毫秒后被中止。

## 如何运行

1.  确保你已经安装了所有必要的依赖：

    ```bash
    npm install @langchain/openai @langchain/community
    ```

2.  在项目根目录下创建一个 `.env` 文件，并填入你的 OpenAI 和 Tavily API 密钥：

    ```
    OPENAI_API_KEY=sk-...
    TAVILY_API_KEY=tvly-...
    ```

3.  运行 `index.ts` 文件：

    ```bash
    npx ts-node src/demo_16_Cancel_Execution/index.ts
    ```

## 适用场景

-   **交互式应用中的用户中断**: 在一个聊天机器人或 Web 应用中，如果用户在等待回答时关闭了页面、或输入了新的问题，你可以使用 `AbortController` 来立即取消当前正在进行的请求，从而释放服务器资源，并为新请求做准备。

-   **资源密集型任务的超时控制**: 对于一些可能耗时很长或消耗大量资源的链，你可以设置一个超时定时器。如果任务在规定时间内没有完成，就通过 `signal` 将其取消，以防止系统资源被过度占用。

-   **构建可取消的工作流**: 在使用 LangGraph 构建复杂的多步代理时，取消执行的能力至关重要。它允许你在工作流的任何步骤中安全地停止执行，例如当检测到错误、或外部条件发生变化时。

-   **优化流式响应的用户体验**: 在流式输出场景下，提前取消可以比使用 `break` 更快地停止数据生成和传输，从而更及时地响应用户操作（如点击“停止生成”按钮），提升应用的响应速度和用户体验。